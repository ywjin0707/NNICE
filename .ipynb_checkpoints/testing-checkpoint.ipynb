{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import backend as K\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directories = [\"../DATA/b_cells_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd4_t_helper_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd14_monocytes_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd34_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd56_nk_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cytotoxic_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/memory_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/naive_cytotoxic_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/naive_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/regulatory_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\"]\n",
    "cell_types = ['B_cell','CD4_helper','CD14','CD34','CD56_NK','CD8_cytotoxic','CD4_CD45RO_memory','CD8_CD45RA_naive','CD4_CD45RA_naive','CD4_CD25_regulatory']\n",
    "bkdata_path = '../DATA/TCGA/TCGA_GDC_HTSeq_Counts.txt'\n",
    "# gene_list_path = '../DATA/Immune Gene Lists/genes.csv'\n",
    "data_paths = ['../DATA/TCGA/TCGA_GDC_HTSeq_TPM.csv',\n",
    "              '../DATA/METABRIC/METABRIC.csv',\n",
    "              '../DATA/SDY67/SDY67_477.csv',\n",
    "              '../DATA/Gene Lists/immport_genelist.csv',\n",
    "              '../DATA/Gene Lists/scdata_genelist_filtered.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureList(paths: list) -> list:\n",
    "    features = None\n",
    "    for path in paths:\n",
    "        mydata = pd.read_csv(path, index_col = 0)\n",
    "        if features == None:\n",
    "            features = set(mydata.index.values.tolist())\n",
    "        else:\n",
    "            features = features.intersection(set(mydata.index.values.tolist()))\n",
    "    features = list(features)\n",
    "    features.sort()\n",
    "    return features\n",
    "\n",
    "class DataPreprocess():\n",
    "    def __init__(self, datadir, celltypes, bkdata_path, features):\n",
    "        '''\n",
    "        Creates preprocessed instance of input data\n",
    "        scdata should be in matrix.mtx within specified folders along with barcodes.tsv and genes.tsv\n",
    "        bkdata should have sample names as columns and gene names as rows\n",
    "        gene_list should have no row or column names/index\n",
    "        '''\n",
    "        self.datadir = datadir\n",
    "        self.celltypes = celltypes\n",
    "        self.scdata = self.load_scdata(self.datadir, self.celltypes)\n",
    "        self.bkdata = pd.read_csv(bkdata_path)\n",
    "        # If there is input gene list, filter out genes not in bkdata or scdata\n",
    "        if features is None:\n",
    "            self.features = self.bkdata.index.drop_duplicates()\n",
    "        else:\n",
    "            self.features = features\n",
    "        # Filter out genes not in gene list\n",
    "        self.scdata = self.scdata[:,self.scdata.var_names.isin(self.features)]\n",
    "        sc.pp.normalize_total(self.scdata, target_sum=1e6) # normalize to sum to 1,000,000\n",
    "        # sc.pp.regress_out(scdata, ['total_counts'], n_jobs=1)\n",
    "        # Transpose, filter out genes not in gene list, then sort column (by gene name)\n",
    "        self.bkdata = self.bkdata.T\n",
    "        self.bkdata = self.bkdata.loc[:,self.bkdata.columns.isin(self.features)].sort_index(axis=1)\n",
    "        self.bkdata = self.bkdata.values.astype(float)\n",
    "    def load_scdata(self, data_directories, cell_types):\n",
    "        # Read and merge 10X Genomics scRNA-seq data\n",
    "        scdata = None\n",
    "        print('Loading single cell dataset')\n",
    "        for d, c in zip(tqdm(data_directories), cell_types):\n",
    "            x = sc.read_10x_mtx(d)\n",
    "            x.obs['celltype'] = [c]*len(x.obs.index)\n",
    "            # Change each observation (cell) name to celltype + barcode\n",
    "            x.obs.set_index(pd.Index([c+'_'+rn[:-2] for rn in x.obs.index]), inplace=True)\n",
    "            if scdata is not None:\n",
    "                scdata = ad.concat([scdata, x])\n",
    "            else:\n",
    "                scdata = x\n",
    "        # Filter out cells and genes\n",
    "        sc.pp.filter_cells(scdata, min_genes=200)\n",
    "        sc.pp.filter_genes(scdata, min_cells=1)\n",
    "        # Search for prefix \"MT-\" (mitochondrial genes) and make new column in variable annotations\n",
    "        # Search for prefix \"RPL/RPS\" for ribosomal genes and \"MRPL/MRPS\" for mitochondrial ribosomal genes\n",
    "        scdata.var['mito'] = scdata.var.index.str.match('^MT-')\n",
    "        scdata.var['ribo'] = scdata.var.index.str.startswith(('RPL','RPS'))\n",
    "        scdata.var['mribo'] = scdata.var.index.str.startswith(('MRPL','MRPS'))\n",
    "        # Calculate QC metrics as per McCarthy et al., 2017 (Scater)\n",
    "        sc.pp.calculate_qc_metrics(scdata, qc_vars=['mito','ribo', 'mribo'], inplace=True)\n",
    "        # Plot QC metrics\n",
    "        # sns.jointplot(x='total_counts', y='n_genes_by_counts', height=8, data=scdata.obs,\n",
    "        #     kind='scatter', hue='celltype')\n",
    "        # sns.jointplot(x='total_counts', y='pct_counts_mito', height=8, data=scdata.obs,\n",
    "        #     kind='scatter', hue='celltype')\n",
    "        # sns.jointplot(x='total_counts', y='pct_counts_ribo', height=8, data=scdata.obs,\n",
    "        #     kind='scatter', hue='celltype')\n",
    "        # sns.jointplot(x='total_counts', y='pct_counts_mribo', height=8, data=scdata.obs,\n",
    "        #     kind='scatter', hue='celltype')\n",
    "        # plt.show()\n",
    "        # Filter out cells with >5% of counts from mitochondria and mitoribosome\n",
    "        # scdata = scdata[scdata.obs.pct_counts_ribo > 30, :]\n",
    "        scdata = scdata[scdata.obs.pct_counts_mito < 5, :]\n",
    "        scdata = scdata[scdata.obs.pct_counts_mribo < 1, :]\n",
    "        return scdata\n",
    "    def __call__(self, whichdata, batch_size=1):\n",
    "        if whichdata == 'scdata':\n",
    "            out = []\n",
    "            print('Dividing single cell dataset into cell types')\n",
    "            for c in tqdm(self.celltypes):\n",
    "                scdata_ = self.scdata[self.scdata.obs.celltype==c].to_df().sort_index(axis=1)\n",
    "                # Add to row index 0 a cell with no gene expression (all zeros)\n",
    "                # zeros = pd.DataFrame(np.zeros((1,scdata_.shape[1])), columns=scdata_.columns.values)\n",
    "                # Expand into batch dimension and repeat 2-D tensor by # of samples per mini batch\n",
    "                # scdata_ = tf.tile(tf.expand_dims(pd.concat([zeros,scdata_]), axis=0), [batch_size,1,1])\n",
    "                out.append(scdata_)\n",
    "        elif whichdata == 'bkdata':\n",
    "            out = self.bkdata\n",
    "        elif whichdata == 'genelist':\n",
    "            out = self.features\n",
    "        else:\n",
    "            raise ValueError('Choose only one of the following: \"scdata\", \"bkdata\", or \"genelist\"')\n",
    "        return out\n",
    "    \n",
    "class Subsampling(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, scdata):\n",
    "        super(Subsampling, self).__init__()\n",
    "        # initialize one layer for each cell type\n",
    "        self.scdata=scdata\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # select {number of cells} of random column indices from scdata with uniform probability\n",
    "        # allows for sampling with replacement (increases variability)\n",
    "        idx = tf.random.uniform(\n",
    "            shape=[inputs],\n",
    "            minval=0, maxval=self.scdata.shape[0]-1,\n",
    "            dtype=tf.int32)\n",
    "        # subset scdata with selected random column indices\n",
    "        subset = tf.gather(self.scdata, idx, axis=1)\n",
    "        return tf.reduce_sum(subset, axis=1)\n",
    "\n",
    "class AdversarialSimulator():\n",
    "\n",
    "    '''\n",
    "    Ref: github.com/eriklindernoren/Keras-GAN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, scdata, n_sim_samples = 1000):\n",
    "        self.scdata = scdata\n",
    "        self.n_sim_samples = n_sim_samples\n",
    "        self.n_celltypes = len(scdata)\n",
    "        self.n_features = scdata[0].shape[1]\n",
    "        optmzr = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        self.Discriminator = self.build_discriminator()\n",
    "        self.Discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optmzr,\n",
    "            metrics=['accuracy'])\n",
    "        self.Simulator = self.build_simulator()\n",
    "        # Simulator takes in Nprop as input and generates simbulk\n",
    "        z = Input(shape=(self.n_celltypes))\n",
    "        img = self.Simulator(z)\n",
    "        # For the combined model, we only train the Simulator\n",
    "        self.Discriminator.trainable = False\n",
    "        # Discriminator takes simbulk as input and determines validity\n",
    "        valid = self.Discriminator(self.simbulk)\n",
    "        # stacked Simulator and Discriminator\n",
    "        self.AdvSim = tf.keras.Model(z, valid)\n",
    "        self.AdvSim.compile(loss='binary_crossentropy', optimizer=optmzr)\n",
    "\n",
    "    def MinMaxNorm(self, x):\n",
    "        x_scaled = tf.math.divide_no_nan(\n",
    "            (x - tf.math.reduce_min(x)),\n",
    "            (tf.math.reduce_max(x) - tf.math.reduce_min(x)))\n",
    "        return x_scaled\n",
    "\n",
    "    def simulated_fractions(self, batch_size):\n",
    "        alpha = [1]*self.n_celltypes\n",
    "        dist = tfp.distributions.Dirichlet(alpha)\n",
    "        nprop = dist.sample([batch_size])\n",
    "        return nprop\n",
    "\n",
    "    def build_simulator(self):\n",
    "        inputs = tf.keras.layers.Input(shape=self.n_celltypes)\n",
    "        x = []\n",
    "        for c in range(self.n_celltypes):\n",
    "            x.append(Subsampling(self.scdata[c])(inputs))\n",
    "        x = tf.keras.layers.Add()(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.math.log1p)(x)\n",
    "        x = tf.keras.layers.LayerNormalization(center=True, scale=True)(x)\n",
    "        outputs = tf.keras.layers.Lambda(lambda x: self.MinMaxNorm)(x)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        inputs = tf.keras.Input(shape=(self.n_features,))\n",
    "        x = tf.keras.layers.Dense(256)(inputs)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = tf.keras.layers.Dense(128)(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        model._name = \"Discriminator\"\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def train(self, X_data, steps=1000):\n",
    "        X_data = self.MinMaxNorm(tf.math.log1p(X_data))\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        for step in range(steps):\n",
    "            '''\n",
    "            Train Discriminator\n",
    "            '''\n",
    "            # Select random subset of X_data equal to batch_size\n",
    "            idx = np.random.randint(0, X_data.shape[0], 1)\n",
    "            bulk = X_data.numpy()[idx]\n",
    "            # Sample Nprop (cell fractions) using Dirichlet distribution\n",
    "            nprop = self.simulated_fractions(batch_size)\n",
    "            # Generate simbulk using Nprop\n",
    "            simbulk = self.Simulator.predict(nprop)\n",
    "            # Train Discriminator\n",
    "            d_loss_real = self.Discriminator.train_on_batch(bulk, valid)\n",
    "            d_loss_fake = self.Discriminator.train_on_batch(simbulk, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            '''\n",
    "            Train Simulator\n",
    "            '''\n",
    "            # Train Simulator (wants Discriminator to make mistakes)\n",
    "            s_loss = self.AdvSim.train_on_batch(nprop, valid)\n",
    "            # Plot the progress\n",
    "            print (\"Step: %d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (step, d_loss[0], 100*d_loss[1], s_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading single cell dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:58<00:00, 11.73s/it]\n",
      "c:\\users\\yw_ji\\documents\\msc thesis\\code\\keras\\scanpy\\scanpy\\preprocessing\\_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "myData = DataPreprocess(data_directories, cell_types, bkdata_path, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing single cell dataset into cell types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3010)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               770816    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 803,841\n",
      "Trainable params: 803,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AdversarialSimulator' object has no attribute 'n_celltype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-285b62f753e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmyModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdversarialSimulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'scdata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-ebb5e455e3c4>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, scdata, n_sim_samples)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptmzr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             metrics=['accuracy'])\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimulator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_simulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;31m# Simulator takes in Nprop as input and generates simbulk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_celltypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-ebb5e455e3c4>\u001b[0m in \u001b[0;36mbuild_simulator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_celltypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_celltype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSubsampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AdversarialSimulator' object has no attribute 'n_celltype'"
     ]
    }
   ],
   "source": [
    "myModel = AdversarialSimulator(myData('scdata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.train(myData('bkdata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga = pd.read_csv(bkdata_path, sep='\\t')\n",
    "tcga = tcga.sort_index()\n",
    "tcga.to_csv('../DATA/TCGA/TCGA_GDC_HTSeq_TPM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abis = pd.read_csv('../DATA/GSE107011/GSE107011_Processed_data_TPM.txt')\n",
    "epic = pd.read_csv('../DATA/EPIC/melanoma_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric = pd.read_csv('../DATA/METABRIC/data_expression_median.txt', sep='\\t', index_col=0)\n",
    "metabric.index.name = None\n",
    "metabric = metabric.iloc[:,1:]\n",
    "metabric = metabric.sort_index()\n",
    "metabric.to_csv('../DATA/METABRIC/METABRIC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdy67_1 = pd.read_csv('../DATA/SDY67/SDY67_EXP13377_RNA_seq.703318.tsv', sep='\\t', index_col=0)\n",
    "sdy67_2 = pd.read_csv('../DATA/SDY67/SDY67_EXP14625_RNA_seq.703317.tsv', sep='\\t', index_col=0)\n",
    "sdy67_1.index.name = None\n",
    "sdy67_2.index.name = None\n",
    "sdy67 = sdy67_1.join(sdy67_2)\n",
    "sdy67 = sdy67.sort_index()\n",
    "sdy67_meta = pd.read_csv('../DATA/SDY67/SDY67-DR34_Subject_2_RNA_sequencing_result.txt', sep='\\t')\n",
    "sdy67_meta['SubjectID'] = [sub+'_'+str(time) for sub, time in zip(list(sdy67_meta['Subject Accession'].values),list(sdy67_meta['Study Time Collected'].values))]\n",
    "sdy67_id = sdy67_meta.reset_index().set_index('Expsample Accession').loc[sdy67.columns.values.tolist(),'SubjectID'].values.tolist()\n",
    "sdy67.columns = sdy67_id\n",
    "sdy67.to_csv('../DATA/SDY67/SDY67_477.csv')\n",
    "\n",
    "sdy67_label = pd.read_csv('../DATA/SDY67/SDY67_extracted_from_mmc7.csv', index_col=0)\n",
    "sdy67_label.index.name = None\n",
    "sdy67_label['Other'] = 0\n",
    "sdy67_label = sdy67_label.fillna(0)\n",
    "sdy67_label = sdy67_label.loc[sdy67.columns,]\n",
    "for i in range(len(sdy67_label)):\n",
    "    sumval = sum(sdy67_label.iloc[i,:])\n",
    "    if sumval >= 100:\n",
    "        sdy67_label.iloc[i,:] = sdy67_label.iloc[i,:]/sumval\n",
    "    else:\n",
    "        sdy67_label.iloc[i,5] = 100-sumval\n",
    "        sdy67_label.iloc[i,:] = sdy67_label.iloc[i,:]/100\n",
    "sdy67_label.to_csv('../DATA/SDY67/SDY67_477_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABIS dataset need to load genes.tsv then match Ensembl id to gene id \n",
    "# EPIC dataset needs fixing\n",
    "abis = pd.read_csv('../DATA/GSE107011/GSE107011_Processed_data_TPM.txt', index_col=0) # EnsDb.Hsapiens.v79, aggregated signals from duplicate probes by max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abis[abis.columns[abis.columns.to_series().str.contains('_PBMC')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set(tcga.index.values.tolist()).intersection(set(metabric.index.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga.T.loc[:,features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureList(paths: list) -> list:\n",
    "    features = None\n",
    "    for path in paths:\n",
    "        mydata = pd.read_csv(path, header=None)\n",
    "        if features == None:\n",
    "            features = set(mydata.index.values.tolist())\n",
    "        else:\n",
    "            features = features.intersection(set(mydata.index.values.tolist()))\n",
    "    features = list(features)\n",
    "    features.sort()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BulkDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, csv_path, features):\n",
    "        self.bkdata = pd.read_csv(csv_path, index_col=0)\n",
    "        self.bkdata = self.bkdata.T.loc[:,features] # when not sorted, add \".sort_index(axis=1)\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.bkdata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.bkdata[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scdata(data_directories, cell_types):\n",
    "    # Read and merge 10X Genomics scRNA-seq data\n",
    "    scdata = None\n",
    "    for d, c in zip(tqdm(data_directories), cell_types):\n",
    "        x = sc.read_10x_mtx(d)\n",
    "        x.obs['celltype'] = [c]*len(x.obs.index)\n",
    "        # Change each observation (cell) name to celltype + barcode\n",
    "        x.obs.set_index(pd.Index([c+'_'+rn[:-2] for rn in x.obs.index]), inplace=True)\n",
    "        if scdata is not None:\n",
    "            scdata = ad.concat([scdata, x])\n",
    "        else:\n",
    "            scdata = x\n",
    "    # Filter out cells and genes\n",
    "    sc.pp.filter_cells(scdata, min_genes=200)\n",
    "    sc.pp.filter_genes(scdata, min_cells=1)\n",
    "    # Search for prefix \"MT-\" (mitochondrial genes) and make new column in variable annotations\n",
    "    # Search for prefix \"RPL/RPS\" for ribosomal genes and \"MRPL/MRPS\" for mitochondrial ribosomal genes\n",
    "    scdata.var['mito'] = scdata.var.index.str.match('^MT-')\n",
    "    scdata.var['ribo'] = scdata.var.index.str.startswith(('RPL','RPS'))\n",
    "    scdata.var['mribo'] = scdata.var.index.str.startswith(('MRPL','MRPS'))\n",
    "    # Calculate QC metrics as per McCarthy et al., 2017 (Scater)\n",
    "    sc.pp.calculate_qc_metrics(scdata, qc_vars=['mito','ribo', 'mribo'], inplace=True)\n",
    "    # Plot QC metrics\n",
    "    # sns.jointplot(x='total_counts', y='n_genes_by_counts', height=8, data=scdata.obs,\n",
    "    #     kind='scatter', hue='celltype')\n",
    "    # sns.jointplot(x='total_counts', y='pct_counts_mito', height=8, data=scdata.obs,\n",
    "    #     kind='scatter', hue='celltype')\n",
    "    # sns.jointplot(x='total_counts', y='pct_counts_ribo', height=8, data=scdata.obs,\n",
    "    #     kind='scatter', hue='celltype')\n",
    "    # sns.jointplot(x='total_counts', y='pct_counts_mribo', height=8, data=scdata.obs,\n",
    "    #     kind='scatter', hue='celltype')\n",
    "    # plt.show()\n",
    "    # Filter out cells with >5% of counts from mitochondria and mitoribosome\n",
    "    # scdata = scdata[scdata.obs.pct_counts_ribo > 30, :]\n",
    "    scdata = scdata[scdata.obs.pct_counts_mito < 5, :]\n",
    "    scdata = scdata[scdata.obs.pct_counts_mribo < 1, :]\n",
    "    return scdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdata = load_scdata(data_directories, cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(scdata[scdata.obs.celltype=='B_cell',scdata.var_names.isin(features)].to_df().sort_index(axis=1).to_numpy()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdata_list = []\n",
    "for c in tqdm(cell_types):\n",
    "    scdata_list.append(torch.Tensor(scdata[scdata.obs.celltype==c, scdata.var_names.isin(features)].to_df().sort_index(axis=1).to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.nn.Linear(5,10)\n",
    "tmp = tmp(torch.Tensor([1.,2.,3.,4.,5.]))\n",
    "dist = torch.distributions.multinomial.Multinomial(total_count=500, logits=tmp)\n",
    "tmp = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tmp:\n",
    "    print(torch.multinomial(torch.Tensor([1]*700), int(i), replacement=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.multinomial.Multinomial(total_count=500, probs=torch.Tensor([[1,4,5,4,7,4],[5,3,4,5,6,2]])).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directories = [\"../DATA/b_cells_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd4_t_helper_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd14_monocytes_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd34_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cd56_nk_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/cytotoxic_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/memory_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/naive_cytotoxic_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/naive_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\",\n",
    "                    \"../DATA/regulatory_t_filtered_gene_bc_matrices/filtered_matrices_mex/hg19/\"]\n",
    "cell_types = ['B_cell','CD4_helper','CD14','CD34','CD56_NK','CD8_cytotoxic','CD4_CD45RO_memory','CD8_CD45RA_naive','CD4_CD45RA_naive','CD4_CD25_regulatory']\n",
    "bkdata_path = '../DATA/TCGA/TCGA_GDC_HTSeq_Counts.txt'\n",
    "gene_list_path = '../DATA/Immune Gene Lists/genes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = DataPreprocess(data_directories, cell_types, bkdata_path, gene_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(np.array(range(100)), axis=1).repeat(100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dns = tf.keras.layers.Dense(10, activation='relu', input_shape=(100,))\n",
    "x = dns(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml = tfp.layers.DistributionLambda(\n",
    "    make_distribution_fn=lambda t: tfp.distributions.DirichletMultinomial(\n",
    "        total_count=500, concentration=t),\n",
    "    convert_to_tensor_fn=lambda s: s.sample(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dml(x[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdata = myData('scdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(scdata[0], [9899,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdata0 = tf.data.Dataset.from_tensors(tf.reshape(scdata[0], [9899,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(scdata0.shuffle(10000).take(500).as_numpy_iterator())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(scdata[0], [9899,-1]).numpy()[list(tf.data.Dataset.range(9899).shuffle(10000).take(500).as_numpy_iterator()),:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idxs = tf.range(tf.shape(inputs)[0])\n",
    "ridxs = tf.random.shuffle(idxs)[:sample_num]\n",
    "rinput = tf.gather(inputs, ridxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(100,)))\n",
    "model.add(tfp.layers.DistributionLambda(\n",
    "    make_distribution_fn=lambda a: tfp.distributions.DirichletMultinomial(\n",
    "        total_count=500, concentration=a)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
